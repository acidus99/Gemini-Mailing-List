<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> Identifying robots (was Re: Open Source Proxy)
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:gemini%40lists.orbitalfox.eu?Subject=Re%3A%20Identifying%20robots%20%28was%20Re%3A%20Open%20Source%20Proxy%29&In-Reply-To=%3C20200723220103.GB186796%40goldfish.localdomain%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="002318.html">
   <LINK REL="Next"  HREF="002324.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>Identifying robots (was Re: Open Source Proxy)</H1>
    <B>Natalie Pendragon</B> 
    <A HREF="mailto:gemini%40lists.orbitalfox.eu?Subject=Re%3A%20Identifying%20robots%20%28was%20Re%3A%20Open%20Source%20Proxy%29&In-Reply-To=%3C20200723220103.GB186796%40goldfish.localdomain%3E"
       TITLE="Identifying robots (was Re: Open Source Proxy)">natpen at natpen.net
       </A><BR>
    <I>Thu Jul 23 23:01:03 BST 2020</I>
    <P><UL>
        <LI>Previous message (by thread): <A HREF="002318.html">Identifying robots (was Re: Open Source Proxy)
</A></li>
        <LI>Next message (by thread): <A HREF="002324.html">Identifying robots (was Re: Open Source Proxy)
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#2320">[ date ]</a>
              <a href="thread.html#2320">[ thread ]</a>
              <a href="subject.html#2320">[ subject ]</a>
              <a href="author.html#2320">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>For the GUS crawl at least, the crawler doesn't identify itself _to_
crawled sites, but it does obey blocks of rules in robots.txt files
according to user-agent. So it works without needing a user-agent
header.

It obeys user-agent of `*`, `indexer`, and `gus` in order of
increasing importance.

There's been some talk of the generic sorts of user-agents in the
past, which I think is a really nice idea. If `indexer` is a
user-agent that both sites and crawlers had some sort of informal
consensus on, then sites wouldn't need to worry about keeping up with
any new indexers popping up.

Some other generic user-agent ideas, iirc, were `archiver` and
`proxy`.

On Thu, Jul 23, 2020 at 04:45:50PM -0400, Sean Conner wrote:
&gt;<i> It was thus said that the Great Jason McBrayer once stated:
</I>&gt;<i> &gt;
</I>&gt;<i> &gt; This is cool, but when you stand it up, don't forget an appropriate
</I>&gt;<i> &gt; robots.txt!
</I>&gt;<i>
</I>&gt;<i>   Question---HTTP has the Use-Agent: header to help identify webbots, but
</I>&gt;<i> Gemini doesn't have that.  How do I instruct a Gemini bot with robots.txt,
</I>&gt;<i> when there's no way for a Gemini bot to identify itself?
</I>&gt;<i>
</I>&gt;<i>   -spc
</I>&gt;<i>
</I></PRE>




















<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message (by thread): <A HREF="002318.html">Identifying robots (was Re: Open Source Proxy)
</A></li>
	<LI>Next message (by thread): <A HREF="002324.html">Identifying robots (was Re: Open Source Proxy)
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#2320">[ date ]</a>
              <a href="thread.html#2320">[ thread ]</a>
              <a href="subject.html#2320">[ subject ]</a>
              <a href="author.html#2320">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.orbitalfox.eu/listinfo/gemini">More information about the Gemini
mailing list</a><br>
</body></html>
