<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> robots.txt for Gemini formalised
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:gemini%40lists.orbitalfox.eu?Subject=Re%3A%20robots.txt%20for%20Gemini%20formalised&In-Reply-To=%3C20201123020541.GE1721%40brevard.conman.org%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="003503.html">
   <LINK REL="Next"  HREF="003505.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>robots.txt for Gemini formalised</H1>
    <B>Sean Conner</B> 
    <A HREF="mailto:gemini%40lists.orbitalfox.eu?Subject=Re%3A%20robots.txt%20for%20Gemini%20formalised&In-Reply-To=%3C20201123020541.GE1721%40brevard.conman.org%3E"
       TITLE="robots.txt for Gemini formalised">sean at conman.org
       </A><BR>
    <I>Mon Nov 23 02:05:41 GMT 2020</I>
    <P><UL>
        <LI>Previous message (by thread): <A HREF="003503.html">robots.txt for Gemini formalised
</A></li>
        <LI>Next message (by thread): <A HREF="003505.html">robots.txt for Gemini formalised
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#3504">[ date ]</a>
              <a href="thread.html#3504">[ thread ]</a>
              <a href="subject.html#3504">[ subject ]</a>
              <a href="author.html#3504">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>It was thus said that the Great Robert khuxkm Miles once stated:
&gt;<i> 
</I>&gt;<i> Is there any good usecase for a proxy User-Agent in robots.txt, other than
</I>&gt;<i> blocking web spiders from being able to crawl gemspace? If not, I would be
</I>&gt;<i> in favor of dropping that part of the definition.
</I>
  I'm in favor of dropping that part of the definition as it doesn't make
sense at all.  Given a web based proxy at &lt;<A HREF="https://example.com/gemini">https://example.com/gemini</A>&gt;, web
crawlers will check for &lt;<A HREF="https://example.com/robots.txt">https://example.com/robots.txt</A>&gt; for guidance, not
&lt;<A HREF="https://example.com/gemini?gemini.conman.org/robots.txt">https://example.com/gemini?gemini.conman.org/robots.txt</A>&gt;.  Web crawlers
will not be able to crawl gemini space for two main reasons:

        1. Most server certificates are self-signed and opt out of the CA
           business.  And even if a crawler where to accept self-signed
          (or non-standard CA signed) certificates, then---

        2. The Gemini protocol is NOT HTTP, so all such HTTP requests will
           fail anyway.

  -spc
</PRE>










<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message (by thread): <A HREF="003503.html">robots.txt for Gemini formalised
</A></li>
	<LI>Next message (by thread): <A HREF="003505.html">robots.txt for Gemini formalised
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#3504">[ date ]</a>
              <a href="thread.html#3504">[ thread ]</a>
              <a href="subject.html#3504">[ subject ]</a>
              <a href="author.html#3504">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.orbitalfox.eu/listinfo/gemini">More information about the Gemini
mailing list</a><br>
</body></html>
