<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> Assuming disallow-all, and some research on robots.txt in Geminispace (Was: Re: robots.txt for Gemini formalised)
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:gemini%40lists.orbitalfox.eu?Subject=Re%3A%20Assuming%20disallow-all%2C%0A%20and%20some%20research%20on%20robots.txt%20in%20Geminispace%20%28Was%3A%20Re%3A%20robots.txt%0A%20for%20Gemini%20formalised%29&In-Reply-To=%3CtERpVvSbQ6NQwl_n8E2nXv-QW3Nt8Mp6YvKCfiVGcwEkI27sWXw3eCc39qXTJqLnTv4HmhORWinNQHxC0A_kFXUewEoW4GG4s3eKiFYopiI%3D%40protonmail.com%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="003559.html">
   <LINK REL="Next"  HREF="003564.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>Assuming disallow-all, and some research on robots.txt in Geminispace (Was: Re: robots.txt for Gemini formalised)</H1>
    <B>Krixano</B> 
    <A HREF="mailto:gemini%40lists.orbitalfox.eu?Subject=Re%3A%20Assuming%20disallow-all%2C%0A%20and%20some%20research%20on%20robots.txt%20in%20Geminispace%20%28Was%3A%20Re%3A%20robots.txt%0A%20for%20Gemini%20formalised%29&In-Reply-To=%3CtERpVvSbQ6NQwl_n8E2nXv-QW3Nt8Mp6YvKCfiVGcwEkI27sWXw3eCc39qXTJqLnTv4HmhORWinNQHxC0A_kFXUewEoW4GG4s3eKiFYopiI%3D%40protonmail.com%3E"
       TITLE="Assuming disallow-all, and some research on robots.txt in Geminispace (Was: Re: robots.txt for Gemini formalised)">krixano at protonmail.com
       </A><BR>
    <I>Thu Nov 26 06:09:54 GMT 2020</I>
    <P><UL>
        <LI>Previous message (by thread): <A HREF="003559.html">Assuming disallow-all, and some research on robots.txt in Geminispace (Was: Re: robots.txt for Gemini formalised)
</A></li>
        <LI>Next message (by thread): <A HREF="003564.html">Assuming disallow-all, and some research on robots.txt in    Geminispace (Was: Re: robots.txt for Gemini formalised)
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#3560">[ date ]</a>
              <a href="thread.html#3560">[ thread ]</a>
              <a href="subject.html#3560">[ subject ]</a>
              <a href="author.html#3560">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Gaah, ok, I hit reply instead of reply all... so my messages were sent directly to the people, lol. I'll repost them here:

I want to point out that making the assumption that a lack of robots.txt
is because servers don't mind they're content being archived is a leap in logic
that doesn't actually follow/make sense. A server/user could have just forgotten
to put a robots.txt, *or* they could have just not known about it.

&gt;<i> A personal example: *I* didn't have a robots.txt on my capsule file until today, but I don't want to be included in archives for various reasons. Presuming consent from the lack of a robots.txt file would have incorrectly guessed my preference, and harmed my privacy. Who else in that 90% is like me? We don't know.
</I>
Exactly! When I first got my server up, I didn't have a robots.txt for the longest time. Some of my content was actually not supposed to be archived because it was dynamic stuff. And other stuff I didn't necessarily want archived.

Christian Seibold

Sent with [ProtonMail](<A HREF="https://protonmail.com/">https://protonmail.com/</A>) Secure Email.

&#8208;&#8208;&#8208;&#8208;&#8208;&#8208;&#8208; Original Message &#8208;&#8208;&#8208;&#8208;&#8208;&#8208;&#8208;
On Wednesday, November 25th, 2020 at 9:10 AM, John Cowan &lt;<A HREF="https://lists.orbitalfox.eu/listinfo/gemini">cowan at ccil.org</A>&gt; wrote:

&gt;<i> On Wed, Nov 25, 2020 at 6:32 AM Nick Thomas &lt;<A HREF="https://lists.orbitalfox.eu/listinfo/gemini">gemini at ur.gs</A>&gt; wrote:
</I>&gt;<i>
</I>&gt;&gt;<i> (Received off-list, but I assume it was *meant* for the list, so
</I>&gt;&gt;<i> replying there)
</I>&gt;<i>
</I>&gt;<i> It was, so thanks. My private messages are labeled (Private message) at the top because I make this mistake a lot.
</I>&gt;<i>
</I>&gt;&gt;<i> Whatever the outcome of the opt-in vs opt-out part of this discussion,
</I>&gt;<i>
</I>&gt;<i> That's the only part that concerns me. A robots.txt spec is good and crawlers/archivers that respect it are fine too, though of course some won't.
</I>&gt;<i>
</I>&gt;<i> I once wrote to the author of a magazine article who had published a simple crawler that it would hammer whatever server it was crawling, since it did not delay between requests or intersperse them with requests to other servers, but simply walked the server's tree depth-first. and that it should respect robots.txt. He wrote back saying &quot;That's the Internet today; deal with it.&quot; I could have answered (but I didn't) that hits are a cost to the server operator, and anyone running his dumb crawler was not only DDOSing, but spending my money for his own purposes.
</I>&gt;<i>
</I>&gt;<i> But I do think that once robots.txt support is in place, no robots.txt = no expressed preference.
</I>&gt;<i>
</I>&gt;&gt;<i> If it's true for people with an explicit preference, it can also be
</I>&gt;&gt;<i> true for people who haven't expressed a preference yet. Since Gemini
</I>&gt;&gt;<i> has a higher standard for user privacy than the web, it can also have a
</I>&gt;&gt;<i> higher standard for these preferences - one that does not rely on
</I>&gt;&gt;<i> presumed consent - if we want it to.
</I>&gt;<i>
</I>&gt;<i> By this logic, nobody should be able to access a Gemini server at all unless the capsule author has expressed a preference for them to do so. But to publish is to expose your work to the public.
</I>&gt;<i>
</I>&gt;&gt;<i> The FAQ immediately above the one you quoted reads:
</I>&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Why isn't the site I'm looking for in the archive?*
</I>&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> Some sites may not be included because the automated crawlers were
</I>&gt;&gt;&gt;<i> unaware of their existence at the time of the crawl. It's also
</I>&gt;&gt;&gt;<i> possible that some sites were not archived because they were
</I>&gt;&gt;&gt;<i> password protected, blocked by robots.txt, or otherwise inaccessible
</I>&gt;&gt;&gt;<i> to our automated systems. Site owners might have also requested that
</I>&gt;&gt;&gt;<i> their sites be excluded from the Wayback Machine.
</I>&gt;<i>
</I>&gt;<i> I interpret that to mean that some sites were not crawled during the period when the Archive was paying attention to robots.txt, and so their content as of that date is unavailable. Note the past tense: &quot;were [...] protected by robots.txt&quot; as opposed to &quot;are protected&quot;.
</I>&gt;<i>
</I>&gt;&gt;<i> If archive.org didn't respect robots.txt at all, it would lend a lot of
</I>&gt;&gt;<i> flavour to the &quot;archiver&quot; virtual user-agent idea in the companion
</I>&gt;&gt;<i> spec, in addition to this discussion. Do you still have doubts after
</I>&gt;&gt;<i> reading this section?
</I>&gt;<i>
</I>&gt;<i> I have no doubt whatever that the crawler doesn't respect robots.txt. I could do a little experiment, though.
</I>&gt;<i>
</I>&gt;<i> John Cowan <A HREF="http://vrici.lojban.org/~cowan">http://vrici.lojban.org/~cowan</A> <A HREF="https://lists.orbitalfox.eu/listinfo/gemini">cowan at ccil.org</A>
</I>&gt;<i> The competent programmer is fully aware of the strictly limited size of his own
</I>&gt;<i> skull; therefore he approaches the programming task in full humility, and among
</I>&gt;<i> other things he avoids clever tricks like the plague. --Edsger Dijkstra
</I>-------------- next part --------------
An HTML attachment was scrubbed...
URL: &lt;<A HREF="https://lists.orbitalfox.eu/archives/gemini/attachments/20201126/ae3e48ea/attachment.htm">https://lists.orbitalfox.eu/archives/gemini/attachments/20201126/ae3e48ea/attachment.htm</A>&gt;
</PRE>








<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message (by thread): <A HREF="003559.html">Assuming disallow-all, and some research on robots.txt in Geminispace (Was: Re: robots.txt for Gemini formalised)
</A></li>
	<LI>Next message (by thread): <A HREF="003564.html">Assuming disallow-all, and some research on robots.txt in    Geminispace (Was: Re: robots.txt for Gemini formalised)
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#3560">[ date ]</a>
              <a href="thread.html#3560">[ thread ]</a>
              <a href="subject.html#3560">[ subject ]</a>
              <a href="author.html#3560">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.orbitalfox.eu/listinfo/gemini">More information about the Gemini
mailing list</a><br>
</body></html>
